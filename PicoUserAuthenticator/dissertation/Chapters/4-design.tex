% Chapter Template

\chapter{Design} % Main chapter title

\label{Chapter4} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 4. \emph{Design}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

\section{Design requirements}
% Motivation for design
The framework evaluation of Picosiblings provides insight as to how the scheme can be improved. We identify as a key downside that it does not guarantee the identity of the owner. This information is mainly inferred from the number of Picosibling shares in the proximity of the Pico. However, anyone may be in possession of the shares, therefore being temporarily granted full authentication privileges. This is reflected in the evaluation by failing to fully offer `resilient-to-theft'' and ``non-disclosability''. Another improvement can be made by introducing ``multi-level-unlocking'', allowing for multiple levels of authentication depending on the confidence in the owner's presence.

% Pico properties that need to be maintained
The Pico design proposed by Stajano \cite{stajano2011pico} claims two properties that need to be supported by the token unlocking mechanism: memory effortless authentication, and continuous authentication\footnote{Continuous authentication is defined by the ability to re-authenticate the user without the need for any physical effort.}. 

% TODO: maybe offer more details or what the requirements are
A requirement when designing the new Pico unlocking mechanism is to fully satisfy the the properties presented in this section.

\section{Proposed solution}
\label{propopsedsol}
% combine multiple authentication mechanisms
The idea explored in this dissertation is to simultaneously use multiple memoryless continuous authentication mechanisms. Each mechanism needs to provide a quantifiable confidence level that will be used in calculating a combined score. This satisfies the Pico design requirements. By combining mechanisms we achieve a higher confidence of correctly identifying the owner. Furthermore, given that each individual mechanism supports continuous authentication, using them simultaneously does not create any inconvenience for the owner.

\subsection*{Multi-level unlocking model}
% multi-level unlocking model
The Pico token should no longer enter a general locked or unlocked state. Its most important secret, the ``Pico Master Key'' should be kept in tamper resistant memory, and be accessible at all times. Using the overall score computed by the proposed mechanism, Pico should offer granular user authentication. Each app needs to be associated with a confidence level defined during the registration process. If the overall confidence of the token exceeds the app's confidence level, then it becomes ``unlocked'' for that specific app. All authentication sessions between Pico and apps need to be managed independently based on this model.

% examples  of authentication mechanisms
The scheme should achieve continuous authentication, while correctly identifying the owner of the token. Therefore, we have decided that authentication mechanisms combined in the scheme need to be based either on biometrics or behavioural analysis. Biometric features that can be used include iris, face, voice, and gait. Behavioural sources of data can be obtained from frequent GPS location, travel paths, wireless network connections, and others.

% how it is different than simple biometrics
The solution offered in this project is different from simply stating that Pico is using biometric data as an unlocking mechanism. The novelty in the design is based on how data is combined in order to compute the overall confidence level. 

\subsection*{Decaying weights}
% each mechanism has a weight
Each mechanism of the scheme is assigned a predefined initial weight based on the level of trust it offers in identifying the owner. This doesn't necessarily need to be related to the precision of the mechanism, but it would be a good indicator for choosing the value.

% decaying weights
Data samples captured for authentication are not always meaningful. For example, accelerometer values for gait recognition are only usable when the user is walking. Depending on how the sensors are integrated with the Pico, camera input for face recognition may not always capture a valid image. The confidence of each mechanism should therefore decrease in time from the last valid authentication sample. This introduces another original feature of this scheme, which is having a decaying weight. Each mechanism starts with a predefined initial value that is decreases in time until a valid user data sample is recorded. 

% example of decaying confidence
% 	TODO: can drop this if needed!
Let us take for example a voice recognition mechanism which samples data every minute. The current weight of the mechanism is 0 so its output is completely ignored. The next sample is recorded, and the voice recognition mechanism outputs a confidence of $70\%$ that the owner is present. After the successful recording, the mechanism weight is updated to its predefined starting value of 30. For the next 10 minutes the owner will be silently reading a book. Since the mechanism only identifies background noise, the weight value of 30 decreases in time. This will induce a smaller impact of the mechanism on the overall score. Each mechanism weight can decrease down to 0, at which point the mechanism is ignored. Computing the overall score will be explained in more detail later in the chapter.

\subsection*{Explicit authentication}
% Explicit authentication mechanisms
We need to consider the case where the owner wants to use Pico to authenticate to a high security app, given a low confidence level from the authenticator. As an example, the Pico owner wants to access their bank account after sitting silent in a dark room for the past hour. Let us say the app requires a confidence level of $95\%$. Due to the lack of valid authentication data, the authenticator only outputs a $20\%$ overall confidence that the owner is present. To solve this problem we have introduced the concept of explicit authentication mechanisms. When the confidence score drops below the threshold required by an app, the user is given the chance to provide valid data samples to one or more mechanisms through an explicit request.

% Combining explicit authentication mechanisms
Combining explicit and continuous authentication can be performed consistently with the current design. Whenever explicit authentication is required, the only difference is that the owner becomes aware of the authentication process. Given that prior to the explicit authentication request the unlocking mechanism didn't produce a high enough confidence, it is assumed that this will also happen prior to that. Therefore, explicit authentication requests need to have a slower decay rate. This will enable the continuous authentication process.

\subsection*{Authentication result}
\label{authfeedback}
% Bayesian update
Each mechanism calculates the probability that the data sample belongs to the owner of the token. After each recording, this probability is updated using Bayes' Law. The process is also known as a Bayesian update, and is descried in the following equation:

\begin{equation} 
\label{eq:bayes1}
P(H|E) = \frac{P(H) * P(E|H)}{P(E)}
\end{equation}

In the equation above:
\begin{itemize} 
	\item E: Stands for evidence and in this case represents the data sample.
	\item H: Stands for hypothesis. In this case we refer to the hypothesis that the owner is present.
	\item $P(H|E)$: Represents the probability of hypothesis $H$ after observing evidence $E$. This is the final probability we are trying to compute after each sample. It is also known as the posterior probability. 
	\item $P(H)$: Represents the probability of hypothesis $H$ before observing evidence $E$. This is also known as the prior probability and is the probability computed at the previous step.
	\item $P(E|H)$: Represents the probability that the current evidence belongs to hypothesis $H$. It is the probability outputted by the mechanism given the sample data.
	\item $P(E)$: This is the model evidence, and has a constant value for all hypotheses.
\end{itemize}

Although $P(E)$ is constant we need its value in order to calculate $P(H|E)$. We can compute it by using the ``Law of total probability'':

\begin{equation} 
\label{eq:lotp}
P(E) = \sum_{n}^{}P(E|H_n) * P(H_n)
\end{equation}

Using equation \ref{eq:lotp}, Bayes' Law \ref{eq:bayes1} can be written as:
\begin{equation} 
\label{eq:bayes2}
P(H|E) = \frac{P(H) * P(E|H)}{\sum_{n}^{}P(E|H_n) * P(H_n)}
\end{equation}

Our model contains only two hypotheses\footnote{Arguably there is a third case where the data sample is not a valid recording of an user. This case is ignored and no probability is computed. The only result in this scenario is the resuming of the decay process in the weight of the mechanism.}: the recording of the data either belongs to the owner, or not. We can therefore consider $P(H)$ to be the probability that the data belongs to the owner and $P(\neg H)$ the probability that the data belongs to someone else. This means the value of $P(\neg H)$ is $1 - P(H)$ and $P(E|\neg H) = 1 - P(E|H)$ Introducing this in equation \ref{eq:bayes2}, the rule for updating the mechanism's probability becomes:

\begin{equation} 
\label{eq:final}
P(H|E) = \frac{P(H) * P(E|H)}{P(H) * P(E|H) + P(\neg H) * P(E|\neg H)}
\end{equation}

Equation \ref{eq:final} represents the final probability that the owner is present given the sampled data. All the variables in this equation are known, for reasons explained above.

% Overall confidence
% 	TODO: update this to have wii and wid (decayed and initial), as well as above when describing the decay rate
We have defined how individual scores are calculated, and that each mechanism has a decaying weight. Using this data we can calculate the overall score of the scheme. This is performed by using the following modified weighted sum:

\begin{equation} 
\label{eq:overall}
P_{Total} = \frac{\sum_{i=1}^{n}(w_{id} * P_i(H|E_i))}{\sum_{i=1}^{n}w_i}
\end{equation}

In equation \ref{eq:overall}, $w_{id}$ represents the decayed weight of mechanism $i$, and $w_i$ is its original weight. We have chosen this model because in a scenario where the token has no sample data to collect, all mechanisms would decrease their weights simultaneously. Using a simple weighted sum, this would misleadingly provide a high overall result, even though all decayed weights would be low.  

\section{Related work}
Clarke et al \cite{clarke2005authentication} present statistics confirming the need for an unlocking scheme different from PINs. They conduct a couple of surveys trying to evaluate the reliability of a PIN in unlocking a mobile phone. The paper reveals a high number of bad practices involved in PIN authentication: reusing the PIN with other authenticators, forgetting the PIN, sharing the PIN with someone else, $45\%$ of owners never change the default factory code, $42\%$ only change it once after buying the device.

A promising result showed in the paper is that $83\%$ of users are willing to accept a biometric authentication mechanism to unlock their devices. The following biometric mechanisms were included in the study: fingerprint analysis, voice recognition, iris recognition, hand recognition, keystroke analysis \cite{clarke2003using}, and face recognition. The paper also shows that $61\%$ of users would accept an unobtrusive biometric continuous authentication mechanism. Using multiple biometrics for continuous authentication is mentioned briefly, but each mechanism is used individually based on what the user is doing. As an example, when the user walks he is authenticated using gait recognition, and while he is speaking on the phone, voice recognition.

In a different paper, Clarke et al \cite{clarke2002acceptance} study PIN alternatives for mobile phone unlocking. The authors conduct a survey with interesting results. A remarkable $11\%$ of participants were not aware of PIN authentication. An average of $81\%$ of participants agree that PINs should be replaced with a mechanism that provides better security. Although they report the need and desire for a different type of phone unlocking, many of them do not use currently available alternatives.

Gregory Williamson \cite{williamson2006enhanced} writes in his PhD dissertation  about the need for an enhanced security authentication mechanism for on-line banking. He proposes a multi-factor authentication model, and presents two interesting options: the traditional one where both mechanisms are required in the multi-factor model (blanket authentication), and one where the second authentication mechanism is only requested from the user if the transaction appears to be risky (risk mode authentication). A risky situation is defined as either an important transaction like withdrawing money, or a transaction made under unusual circumstances such as using an unknown device. 

Risk mode authentication is similar in concept with the explicit authentication request used in our proposed token unlocking scheme. Furthermore, Williamson shows that $75\%$ of users agree with having biometric authentication as a second factor authentication for passwords. This shows promising results in adopting our scheme for token unlocking purposes.

Elena Vildjiounaite et al describe in their paper \cite{vildjiounaite2007increasing} a similar authentication mechanism based on combining biometric authentication data on mobile phone devices. The authors explore an alternative to PINs based on a two stage ``risk mode authentication''. The first stage combines biometric data in order to achieve continuous authentication. This is achieved by training a cascade classifier to a target false acceptance rate (FAR)\footnote{The false acceptance rate is the equivalent of false positive precision. It is the probability of incorrectly granting authentication privileges to an user}. Data from mechanisms is merged using a weighted sum fusion rule. Mechanism weights are chosen based on their error rates. The second stage is only enabled if the cascade classifier does not identify the owner as being present. In low noise scenarios, continuous authentication is achieved without the need for an explicit challenge $80\%$ of the time. In noisy situations (city and car noise), the percentage drops ranging from $40$ to $60\%$. The cascade classifier was trained with a FAR of $1\%$, with results showing a false rejection rate (FRR)\footnote{The false rejection rate is the probability of incorrectly denying access to the rightful owner.} of only $3$ to $7\%$.

The paper by Elena Vildjiounaite et al \cite{vildjiounaite2007increasing} is similar with the solution proposed in this dissertation. It also combines multiple authentication mechanisms, each being assigned different weights. Differences between the two are the fact that weights are maintained static over time. The overall sum is computed differently, and there is no mention of Bayesian updates or probabilities. Furthermore, the authors use a classifier instead of producing a confidence level, which cannot be used for granting different levels of security. The results presented by this paper are however encouraging, showing that continuous authentication presents good results using multiple biometric authentication mechanisms.

\section{Conclusions}
% Conclusion
We have designed a new Pico unlocking mechanism that supports Pico's claims for continuous and memory effortless authentication. The scheme is guaranteed to improve on the existing Picosiblings solution at least by offering a better way of correctly identifying its owner.  

% TODO: sounds a bit bad..
An evaluation of the scheme is not yet offered because mechanisms such as ``Negligible-cost-per-user'' are implementation dependent. The next chapter will present a prototype solution. This offers a better definition of the scheme, that can be evaluated using the token unlocking assessment framework. The results will be compared with the current Picosiblings implementation allowing for further analysis and conclusions.


