\section{Sample Data and Experimentation}
\noindent
\rule{7.0in}{.013in}

\input{data}

\subsection{Comparison Setup}

The main idea was to compare combinations (in MARF: {\it configurations})
of different methods and variations within them in terms of recognition
rate performance. That means that having several preprocessing modules, several feature
extraction modules, and several classification modules, we can (and did)
try all their possible combinations.

That includes:

\begin{enumerate}
	\item Preprocessing: No-filtering (just normalization), low-pass, high-pass,
	      band-pass, and high-frequency boost filters.
	\item Feature Extraction: FFT/LPC/Random algorithms comparison
	\item Clasification: Distance classifiers, such as Chebyshev, Euclidean,
	      Minkowski, and Mahalanobis distances, as well as Neural Network.
\end{enumerate}


For this purpose we have written a \verb+SpeakerIdentApp+, a command-line application
for TI speaker identification. We ran it for every possible configuration
with the following script, namely \verb+testing.sh+:

\vspace{15pt}
\hrule
{\scriptsize \input{testing-sh}}
\hrule
\vspace{15pt}

See the results section (\ref{sect:results}) for results analysis.

\subsection{What Else Could/Should/Will Be Done}

There is a lot more that we realistically could do, but due to lack of time, these things
are not in yet. If you would like to contribute, let us know.

\subsubsection{Combination of Feature Extraction Methods}

For example, assuming we use a combination of LPC coefficients and F0
estimation, we could compare the results of different combinations of
these, and discuss them later. Same with the
Neural Nets (modifying number of layers and number or neurons, etc.).

We could also do a 1024 FFT analysis and compare it against a 128 FFT
analysis.  (That is, the size of the resulting feature vector would be 512 or 64 respectively).
With LPC, one can specify the number of coefficients you want, the more you
have the more precise the analysis will be.

\subsubsection{Entire Recognition Path}

\verb+LPC+ module is used to generate a mean vector of LPC coefficients for
the utterance. F0 is used to find the average fundamental frequency of the
utterance. The results are concatenated to form the output vector, in a
particular order. The classifier would take into account the weighting of
the features: Neural Network would do so implicitly if it benefits the speaker
matching, and stochastic can be modified to give more weight to the F0 or
vice versa, depending on what we see best (i.e.: the covariance matrix in the
Mahalanobis distance (\ref{sect:mahalanobis})).

\subsubsection{More Methods}

Things like F0, Endpointing, Stochastic, and some other methods have not made to this release.
More detailed on this aspect, please refer to the TODO list in the Appendix.
