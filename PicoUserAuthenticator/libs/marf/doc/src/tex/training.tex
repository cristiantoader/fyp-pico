\noindent
{\bf Training}

For training we will be using sets of feature vectors created by FFT or
LPC and passing them to a NNet or something like we discussed alast night
(cluster, or rather probabilistics "cluster"). But I think there are some
issues:

[1] Mapping. We will need a record of Speakers and ID for these speakers.
This can be the same for NNet and Stochastic methods so long as the NNet
will return the proper number and the "clusters" in the Stochastic module have
proper labelling. We will also need a mechanism for adding speakers in
marf (esp. if were to add a speaker during the demo!).

[2] Feature vector generation. I think the best way to do this is for each
application using marf to specify a feature file or directory which will
contain lines/files with the following info:

[a1, a2, ... , an] : <speaker id>

Retraining for a new speaker would involve two phases 1) appending the
features to the file/dir, then 2) re-training the models. The
Classification modules will be aware of the scheme and re-train on all data
required.


> Clusters? I was not there for the 2nd half, could ya elaborate?
> Define clusters in our context.

Given a set of feature vectors in n-dimentional space, if we want these to
represent m "items" (in our case, speakers), we can make groupings of
these vectors with a center point $c_{i}$ (ie: m center points which will
then represent the "items"). Suen discussed an interative algorithm to find
the optimal groupings (or clusters), but I forgot to fill you in :-(.

Anyway, I don't believe that Suen's clustering stuff is at all useful, as
we will know, through info from training, which speaker is associated with
the feature vector and can create the "cluters" with that information.

So for NNet: No clusters, just regular NNet training.

So for Stochastic: Clusters (kind of). I believe that we need to represent
a gaussian curve with a mean vector and a co-variance matrix. This will be
created from the set of featue vectors for the speaker. But again, we know
who it is so the Optimal Clustering business is useless. If we do get
stochastic done :-(
